# ğŸ§  [Embedding Models: From Architecture to Implementation](https://www.deeplearning.ai/short-courses/embedding-models-from-architecture-to-implementation/)

Welcome to the "Embedding Models: From Architecture to Implementation" course! ğŸ§‘â€ğŸ« The course delves deep into the architecture and capabilities of embedding models, widely used in AI applications to capture the meaning of words and sentences.

## ğŸ“˜ Course Summary
In this course, youâ€™ll explore the evolution of embedding models, from word to sentence embeddings, and build and train a simple dual encoder model. ğŸ§  The hands-on approach will enable you to grasp the technical concepts behind embedding models and how to effectively use them.

**Detailed Learning Outcomes:**
1. ğŸ§© **Embedding Models**: Learn about word embedding, sentence embedding, and cross-encoder models, and how they are utilized in Retrieval-Augmented Generation (RAG) systems.

<p align="center">
<img src="images/l1_1.png" height="300"> 
</p>

2. ğŸ§  **Transformer Models**: Understand how transformer models, specifically BERT (Bi-directional Encoder Representations from Transformers), are trained and used in semantic search systems.

<p align="center">
<img src="images/l3_1.png" height="300"> 
<img src="images/l3_2.png" height="300"> 
</p>

3. ğŸ—ï¸ **Dual Encoder Architecture**: Gain knowledge of the evolution of sentence embedding and understand the formation of the dual encoder architecture.

<p align="center">
<img src="images/l3_4.png" height="350"> 
<img src="images/l4_1.png" height="350"> 
</p>

4. ğŸ”§ **Training with Contrastive Loss**: Use contrastive loss to train a dual encoder model, with one encoder trained for questions and another for responses.
<p align="center">
<img src="images/l5_1.png" height="200"> 
<img src="images/l5_2.png" height="200"> 
</p>

5. ğŸ” **RAG Pipeline**: Utilize separate encoders for questions and answers in a RAG pipeline and observe the differences in retrieval effectiveness compared to a single encoder model.
<p align="center">
<img src="images/l5_3.png" height="350"> 
<img src="images/l5_4.png" height="350"> 
</p>

## ğŸ”‘ Key Points
- ğŸ›ï¸ **In-depth Understanding**: Gain a deep understanding of embedding model architecture and learn how to train and use them effectively in AI applications.
- ğŸ§© **Embedding Models in Practice**: Learn how to apply different embedding models such as Word2Vec and BERT in various semantic search systems.
- ğŸ‹ï¸ **Dual Encoder Training**: Build and train dual encoder models using contrastive loss to enhance the accuracy of question-answer retrieval applications.

## ğŸ‘©â€ğŸ« About the Instructor
- ğŸ‘¨â€ğŸ« **Ofer Mendelevitch**: Head of Developer Relations at Vectara, Ofer brings extensive experience in embedding models and their implementation in real-world AI applications.

ğŸ”— To enroll in the course or for further information, visit ğŸ“š [deeplearning.ai](https://www.deeplearning.ai/short-courses/).
